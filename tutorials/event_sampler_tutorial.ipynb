{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVENT SAMPLER TUTORIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial describes how to  simulate an observation of a sky field, starting from a given IRF and a Sky model. The output of this process is the creation of a .fits photon event list. \n",
    "The core of the simulation lies into the Gammapy `MapDatasetEventSampler` class. The class bases its capabilities on the inverse cumulative distribution function (https://en.wikipedia.org/wiki/Cumulative_distribution_function#Inverse_distribution_function_(quantile_function)). \n",
    "\n",
    "The `MapDatasetEventSampler` takes in input a `Dataset` object from which it evaluates a map of predicted counts per bin and it then samples the events giving true coordinates, true energies and times of the events. The class then can also apply IRF corrections (i.e. the PSF and the energy dispersion) in order to reconstruct the coordinates and the energies of the sampled events. \n",
    "\n",
    "The metadata in the event-list are then catched from an `Observation` object. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import copy\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from gammapy.data import DataStore, GTI, Observation\n",
    "from gammapy.datasets import MapDataset, MapDatasetEventSampler\n",
    "from gammapy.maps import MapAxis, WcsGeom, Map\n",
    "from gammapy.irf import load_cta_irfs\n",
    "from gammapy.makers import MapDatasetMaker\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    Model, Models, SkyModel, \n",
    "    PowerLawSpectralModel, \n",
    "    PointSpatialModel,\n",
    "    GaussianSpatialModel,\n",
    "    SkyDiffuseCube\n",
    ")\n",
    "from regions import CircleSkyRegion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Sky model\n",
    "First of all, let's define a Sky model for a point-like source centered 0.5 deg far from the Galactic Center and with a power-law spectral shape. We then save the model into a yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_model_pwl = PowerLawSpectralModel(index=2,amplitude=\"1e-12 TeV-1 cm-2 s-1\", reference='1 TeV')\n",
    "spatial_model_point = PointSpatialModel(lon_0= \"0 deg\", lat_0=\"0.5 deg\", frame='galactic')\n",
    "sky_model_pntpwl = SkyModel(spectral_model=spectral_model_pwl, spatial_model=spatial_model_point)\n",
    "\n",
    "models_pntpwl = Models([sky_model_pntpwl])\n",
    "\n",
    "file_model = \"point-pwl.yaml\"\n",
    "models_pntpwl.write(file_model, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset\n",
    "In this section we show how to create the dataset needed for the simulation (for more info about datasets, please visit https://docs.gammapy.org/dev/notebooks/analysis_2.html#Preparing-reduced-datasets-geometry). \n",
    "\n",
    "Hereafter, we select the IRF from the South configuration of the CTA DC1 to perform our observation simulations. We set the pointing position of the simulated field at the Galactic Center and we fix the exposure time to 8 hr. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRF_FILE = \"$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits\"\n",
    "\n",
    "POINTING = SkyCoord(0.0, 0.0, frame=\"galactic\", unit=\"deg\")\n",
    "LIVETIME = 8 * u.hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the energy axis (true and reconstruncted), the migration axis and the geometry of the observation. \n",
    "\n",
    "We note that this is crucial point as the spatial and energetic binning needs to be very fine. In particular, we suggest to define the energies setting a minimum binning of least 10-20 bins per decade. Instead the spatial binning can be different from source to source and we suggest to adopt a binning significantly smaller than source size.\n",
    "\n",
    "\n",
    "Here, we set the geometry of the dataset to a field of view of 4degx4deg, adopting a binsize of 0.02 deg which is enough for the examples that will be shown hereafter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset config\n",
    "ENERGY_AXIS = MapAxis.from_energy_bounds(\"0.1 TeV\", \"100 TeV\", nbin=10, per_decade=True)\n",
    "ENERGY_AXIS_TRUE = MapAxis.from_energy_bounds(\"0.03 TeV\", \"300 TeV\", nbin=20, per_decade=True, name=\"energy_true\")\n",
    "MIGRA_AXIS = MapAxis.from_bounds(0.5, 2, nbin=150, node_type=\"edges\", name=\"migra\")\n",
    "\n",
    "WCS_GEOM = WcsGeom.create(\n",
    "    skydir=POINTING, width=(4, 4), binsz=0.02, frame=\"galactic\", axes=[ENERGY_AXIS]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generate dataset selecting from the IRF the background model, the psf and the edisp. We create an `Observation` object that containts the pointing position, the GTIs and the IRFs. The datase thus created can be saved into a FITS file simply the `write()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irfs = load_cta_irfs(IRF_FILE)\n",
    "observation = Observation.create(\n",
    "    obs_id=1001, pointing=POINTING, livetime=LIVETIME, irfs=irfs\n",
    ")\n",
    "\n",
    "empty = MapDataset.create(WCS_GEOM, energy_axis_true=ENERGY_AXIS_TRUE, migra_axis=MIGRA_AXIS)\n",
    "maker = MapDatasetMaker(selection=[\"exposure\", \"background\", \"psf\", \"edisp\"])\n",
    "dataset = maker.run(empty, observation)\n",
    "\n",
    "dataset.write('dataset.fits.gz', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate the source + background events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate the Sky model, we need to provide the Sky model to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.models.extend(models_pntpwl)\n",
    "print(dataset.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create an `Observation` object, from which the event-sampler will take the meta-data to be written in the ouput event list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_id=1\n",
    "observation = Observation.create(\n",
    "    obs_id=obs_id, pointing=POINTING, livetime=LIVETIME, irfs=irfs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step shows how to sample the events with the `MapdatasetEventSampler` class. The class requests a random number seed generator that we set with `random_state=0`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = MapDatasetEventSampler(random_state=0)\n",
    "events = sampler.run(dataset, observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the event-sampler is an event list with coordinates, energies and time of arrivals of the source and background events. Source and background events are flagged by the MC_ID identifier (0 for the background and 2 for the source)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Source events: {len(np.where(events.table['MC_ID']==2)[0])}\")\n",
    "print(f\"Background events: {len(np.where(events.table['MC_ID']==0)[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.table.write(\"events_0001.fits.gz\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a skymap\n",
    "A skymap of the simulated events is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Map.create(frame=\"galactic\", skydir=(0, 0.), binsz=0.02, npix=(150, 150))\n",
    "counts.fill_events(events)\n",
    "counts.plot(add_cbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the simulated data\n",
    "We can now check the sake of the event sampling by fitting the data (a tutorial of source fitting is here https://docs.gammapy.org/dev/notebooks/analysis_2.html). We make use of the same Sky model adopted for the simulation. \n",
    "Hence, we firstly read the dataset and the model file, and we fill the dataset with the events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MapDataset.read(\"dataset.fits.gz\")\n",
    "models_sim_point = Models.read(\"point-pwl.yaml\")\n",
    "\n",
    "counts = Map.from_geom(WCS_GEOM)\n",
    "counts.fill_events(events)\n",
    "dataset.counts = counts\n",
    "dataset.models.extend(models_sim_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the data and look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = Fit([dataset])\n",
    "result = fit.run(optimize_opts={\"print_level\": 1})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.parameters.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are quite satisfactory and consistent with the simulated parameters within ~1 sigma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_model_gauss = GaussianSpatialModel(lon_0= \"0 deg\", lat_0=\"0 deg\", sigma=\"0.3 deg\", frame='galactic')\n",
    "sky_model_pntgaus = SkyModel(spectral_model=spectral_model_pwl, spatial_model=spatial_model_gauss)\n",
    "\n",
    "models_pntgaus = Models([sky_model_pntgaus])\n",
    "\n",
    "file_model = \"gauss-pwl.yaml\"\n",
    "models_pntgaus.write(file_model, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MapDataset.read(\"dataset.fits.gz\")\n",
    "dataset.models.extend(models_pntgaus)\n",
    "print(dataset.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = MapDatasetEventSampler(random_state=0)\n",
    "events = sampler.run(dataset, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Map.create(frame=\"galactic\", skydir=(0, 0.), binsz=0.02, npix=(150, 150))\n",
    "counts.fill_events(events)\n",
    "counts.smooth(0.04 * u.deg).plot(add_cbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MapDataset.read(\"dataset.fits.gz\")\n",
    "models_sim_pntgaus = Models.read(\"gauss-pwl.yaml\")\n",
    "\n",
    "counts = Map.from_geom(WCS_GEOM)\n",
    "counts.fill_events(events)\n",
    "dataset.counts = counts\n",
    "dataset.models.extend(models_sim_pntgaus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = Fit([dataset])\n",
    "result = fit.run(optimize_opts={\"print_level\": 1})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.parameters.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended source using a template\n",
    "Let's now see the case of the event sampling of a template map. Here we use the ... that it is possible to find here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuse = SkyDiffuseCube.read(\n",
    "    \"$GAMMAPY_DATA/fermi-3fhl-gc/gll_iem_v06_gc.fits.gz\"\n",
    ")\n",
    "models_diffuse = Models([diffuse])\n",
    "\n",
    "file_model = \"diffuse.yaml\"\n",
    "models_diffuse.write(file_model, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MapDataset.read(\"dataset.fits.gz\")\n",
    "dataset.models.extend(models_diffuse)\n",
    "print(dataset.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = MapDatasetEventSampler(random_state=0)\n",
    "events = sampler.run(dataset, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate multiple observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = np.array([0, 5, 9]) * u.hr\n",
    "tmax = np.array([2, 6.5, 12]) * u.hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obs_id in np.arange(3):\n",
    "    observation = Observation.create(\n",
    "        obs_id=1001, pointing=POINTING, \n",
    "        tstart=tmin[obs_id], tstop=tmax[obs_id],\n",
    "        livetime=tmax[obs_id]-tmin[obs_id], \n",
    "        irfs=irfs\n",
    "    )\n",
    "    empty = MapDataset.create(WCS_GEOM, energy_axis_true=ENERGY_AXIS_TRUE, migra_axis=MIGRA_AXIS)\n",
    "    maker = MapDatasetMaker(selection=[\"exposure\", \"background\", \"psf\", \"edisp\"])\n",
    "    dataset = maker.run(empty, observation)\n",
    "    dataset.write(f'dataset_{obs_id:04d}.fits.gz', overwrite=True)\n",
    "\n",
    "    dataset.models.extend(models_pntgaus)\n",
    "    sampler = MapDatasetEventSampler(random_state=0)\n",
    "    events = sampler.run(dataset, observation)\n",
    "    events.table.write(f\"events_{obs_id:04d}.fits.gz\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"./\")\n",
    "paths = list(path.rglob(\"events*.fits.gz\"))\n",
    "data_store = DataStore.from_events_files(paths)\n",
    "observations = data_store.get_observations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Change the spatial model and the spectrum of the simulated Sky model;\n",
    "- Include a temporal model in the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
