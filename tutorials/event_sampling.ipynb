{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how to generate a Model, a MapDataset and how to fit the data, please refer to the `~gammapy.modeling.models.SkyModel` and [simulate_3d](simulate_3d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context \n",
    "\n",
    "This tutorial describes how to sample events for an observation of a given Sky model and IRF. The main aim of the tutorial is to explain how to set the minimal configuration for the event sampling and how to obtain an output photon event list.\n",
    "\n",
    "The core of the simulation lies into the Gammapy `~gammapy.datasets.MapDatasetEventSampler` class, which is based on the inverse cumulative distribution function [(Inverse CDF)](https://en.wikipedia.org/wiki/Cumulative_distribution_function#Inverse_distribution_function_(quantile_function)). \n",
    "\n",
    "The `~gammapy.datasets.MapDatasetEventSampler` takes in input a `~gammapy.datasets.Dataset` object containing the Sky model. The class evaluates the map of predicted counts per bin and then samples it, giving in output a set of events with true coordinates, true energies and times of arrival. It is also possible to then apply IRF corrections (i.e. PSF and energy dispersion) in order to obtain reconstructed coordinates and energies of the sampled events. \n",
    "\n",
    "The metadata in the event-list are then catched from an `gammapy.data.Observations` object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "To sample events from a given Sky model, obtaining an event-list with coordinates, energies and times for each event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed approach\n",
    "\n",
    "In this section we show how to define an `gammapy.data.Observations` and to create the `~gammapy.datasets.Dataset` object needed for the event sampling (for more info on `~gammapy.datasets.Dataset` objects, please visit this [link](https://docs.gammapy.org/dev/notebooks/analysis_2.html#Preparing-reduced-datasets-geometry)). We define the Sky model and then we sample events from that. We show how to do it for a point-like source and a template map. We finally check consistency by fitting the sampled events with the same Sky model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "As usual, we'll start with some general imports...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import copy\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from gammapy.data import DataStore, GTI, Observation\n",
    "from gammapy.datasets import MapDataset, MapDatasetEventSampler\n",
    "from gammapy.maps import MapAxis, WcsGeom, Map\n",
    "from gammapy.irf import load_cta_irfs\n",
    "from gammapy.makers import MapDatasetMaker\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    Model, Models, SkyModel, \n",
    "    PowerLawSpectralModel, \n",
    "    PointSpatialModel,\n",
    "    GaussianSpatialModel,\n",
    "    SkyDiffuseCube\n",
    ")\n",
    "from regions import CircleSkyRegion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an Observation\n",
    "\n",
    "We firstly create an `gammapy.data.Observations` object that contains the pointing position, the GTIs and the reference IRFs. \n",
    "\n",
    "Hereafter, we consider the IRF of the South configuration of the CTA DC1. We set the pointing position of the simulated field at the Galactic Center and we fix the exposure time to 1 hr.\n",
    "\n",
    "Let's start with some initial settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRF_FILE = \"$GAMMAPY_DATA/cta-1dc/caldb/data/cta/1dc/bcf/South_z20_50h/irf_file.fits\"\n",
    "\n",
    "POINTING = SkyCoord(0.0, 0.0, frame=\"galactic\", unit=\"deg\")\n",
    "LIVETIME = 1 * u.hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irfs = load_cta_irfs(IRF_FILE)\n",
    "observation = Observation.create(\n",
    "    obs_id=1001, pointing=POINTING, livetime=LIVETIME, irfs=irfs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the MapDataset\n",
    "\n",
    "Let's generate the `~gammapy.datasets.Dataset` object: we define the energy axes (true and reconstruncted), the migration axis and the geometry of the observation. \n",
    "\n",
    "*This is a crucial point for the correct configuration of the event sampler. Indeed the spatial and energetic binning should be treaten carefully and the finer the better. For this reason, we suggest to define the energy axes by setting a minimum binning of least 10-20 bins per decade for all the sources of interest. The spatial binning may instead be different from source to source and, at first order, it should be adopted a binning significantly smaller than the expected source size.*\n",
    "\n",
    "For the examples that will be shown hereafter, we set the geometry of the dataset to a field of view of 2degx2deg and we  bin the spatial map with pixels of 0.02 deg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENERGY_AXIS = MapAxis.from_energy_bounds(\"0.1 TeV\", \"100 TeV\", nbin=10, per_decade=True)\n",
    "ENERGY_AXIS_TRUE = MapAxis.from_energy_bounds(\"0.03 TeV\", \"300 TeV\", nbin=20, per_decade=True, name=\"energy_true\")\n",
    "MIGRA_AXIS = MapAxis.from_bounds(0.5, 2, nbin=150, node_type=\"edges\", name=\"migra\")\n",
    "\n",
    "WCS_GEOM = WcsGeom.create(\n",
    "    skydir=POINTING, width=(2, 2), binsz=0.02, frame=\"galactic\", axes=[ENERGY_AXIS]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, the dataset is creating by selecting the effective area, background model, the PSF and the Edisp from the IRF. The dataset thus created can be saved into a FITS file just using the `write()` function. We put it into the `evt_sampling` sub-folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "empty = MapDataset.create(WCS_GEOM, energy_axis_true=ENERGY_AXIS_TRUE, migra_axis=MIGRA_AXIS)\n",
    "maker = MapDatasetMaker(selection=[\"exposure\", \"background\", \"psf\", \"edisp\"])\n",
    "dataset = maker.run(empty, observation)\n",
    "\n",
    "dataset.write('./evt_sampling/dataset.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Sky model: a point-like source\n",
    "\n",
    "First of all, let's define a Sky model (see how to create it [here](https://docs.gammapy.org/dev/notebooks/models.html)) for a point-like source centered 0.5 deg far from the Galactic Center and with a power-law spectral shape. We then save the model into a yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_model_pwl = PowerLawSpectralModel(index=2,amplitude=\"1e-12 TeV-1 cm-2 s-1\", reference='1 TeV')\n",
    "spatial_model_point = PointSpatialModel(lon_0= \"0 deg\", lat_0=\"0.5 deg\", frame='galactic')\n",
    "sky_model_pntpwl = SkyModel(spectral_model=spectral_model_pwl, spatial_model=spatial_model_point)\n",
    "\n",
    "models_pntpwl = Models([sky_model_pntpwl])\n",
    "\n",
    "file_model = \"./evt_sampling/point-pwl.yaml\"\n",
    "models_pntpwl.write(file_model, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the source and background events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can finally add the `~gammapy.modeling.models.SkyModel` we want to simulate to the `~gammapy.datasets.Dataset` container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.models.extend(models_pntpwl)\n",
    "print(dataset.models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step shows how to sample the events with the `~gammapy.datasets.MapDatasetEventSampler` class. The class requests a random number seed generator (that we set with `random_state=0`), the `~gammapy.datasets.Dataset` and the `gammapy.data.Observations` object. From the latter, the `~gammapy.datasets.MapDatasetEventSampler` class takes all the meta data information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sampler = MapDatasetEventSampler(random_state=0)\n",
    "events = sampler.run(dataset, observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the event-sampler is an event list with coordinates, energies and time of arrivals of the source and background events. Source and background events are flagged by the MC_ID identifier (where 0 is the default identifier for the background)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Source events: {len(np.where(events.table['MC_ID']==2)[0])}\")\n",
    "print(f\"Background events: {len(np.where(events.table['MC_ID']==0)[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the properties of the simulated events as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write the photon event list to a FITS file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.table.write(\"./evt_sampling/events_0001.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now load the event list with `Datastore.from_events_files()` and make your own analysis following the instructions in [`analysis_2`](https://docs.gammapy.org/dev/notebooks/analysis_2.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a skymap\n",
    "A skymap of the simulated events is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Map.create(frame=\"galactic\", skydir=(0, 0.), binsz=0.02, npix=(100, 100))\n",
    "counts.fill_events(events)\n",
    "counts.plot(add_cbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the simulated data\n",
    "We can now check the sake of the event sampling by fitting the data (a tutorial of source fitting is [here](https://docs.gammapy.org/dev/notebooks/analysis_2.html#Fit-the-model) and [here](https://docs.gammapy.org/dev/notebooks/simulate_3d)). We make use of the same `~gammapy.modeling.models.SkyModel` adopted for the simulation. \n",
    "Hence, we firstly read the `~gammapy.datasets.Dataset` and the model file, and we fill the `~gammapy.datasets.Dataset` with the sampled events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MapDataset.read(\"./evt_sampling/dataset.fits\")\n",
    "models_sim_point = Models.read(\"./evt_sampling/point-pwl.yaml\")\n",
    "\n",
    "counts = Map.from_geom(WCS_GEOM)\n",
    "counts.fill_events(events)\n",
    "dataset.counts = counts\n",
    "dataset.models.extend(models_sim_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the data and look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fit = Fit([dataset])\n",
    "result = fit.run(optimize_opts={\"print_level\": 1})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.parameters.to_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results looks great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended source using a template\n",
    "The event sampler can also work with a template `~gammapy.modeling.models.SkyModel`.\n",
    "Here we use the interstellar emission model map of the Fermi 3FHL, which can found in the GAMMAPY data repository.\n",
    "\n",
    "We proceed following the same steps showed and we finally have a look at the events properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuse = SkyDiffuseCube.read(\n",
    "    \"$GAMMAPY_DATA/fermi-3fhl-gc/gll_iem_v06_gc.fits.gz\"\n",
    ")\n",
    "models_diffuse = Models([diffuse])\n",
    "\n",
    "file_model = \"./evt_sampling/diffuse.yaml\"\n",
    "models_diffuse.write(file_model, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MapDataset.read(\"./evt_sampling/dataset.fits\")\n",
    "dataset.models.extend(models_diffuse)\n",
    "print(dataset.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sampler = MapDatasetEventSampler(random_state=0)\n",
    "events = sampler.run(dataset, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Read simulated event lists with Datastore.from_events_lists\n",
    "Here we show how to simulate a set of event lists of the same Sky model, but with different GTIs. We make use of the settings we applied previously.\n",
    "Let's define the GTI firstly, chosing a time start and a duration of the observation: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmin = [1, 5, 7] * u.hr\n",
    "# livetime = [1, 1, 1] * u.hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- We then simulate the event lists and we save them into a fits file: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(len(tmin)):\n",
    "#     observation = Observation.create(\n",
    "#         obs_id=i, pointing=POINTING, \n",
    "#         tstart=tmin[i], livetime=livetime[i],\n",
    "#         irfs=irfs\n",
    "#     )\n",
    "#     print(observation)\n",
    "\n",
    "#     dataset = maker.run(empty, observation)\n",
    "#     dataset.models.extend(models_pntpwl)\n",
    "\n",
    "#     events = sampler.run(dataset, observation)\n",
    "#     events.table.write(f\"./evt_sampling/events_{i:04d}.fits\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- The event lists can loaded into a DataStore with the function `from_events_files()`: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = Path(\"./\")\n",
    "# paths = list(path.rglob(\"events*.fits\"))\n",
    "# data_store = DataStore.from_events_files(paths)\n",
    "# observations = data_store.get_observations()\n",
    "# print(data_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- The data can be now treated as explained [here](...) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "- Try to sample events for an extended source (e.g. a radial gaussian morphology);\n",
    "- Change the spatial model and the spectrum of the simulated Sky model;\n",
    "- Include a temporal model in the simulation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
